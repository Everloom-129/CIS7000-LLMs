# CIS 7000: Large Language Models (Fall 2024)
CIS7000@UPenn, Large Language Models (Fall 2024)

https://llm-class.github.io/

## General Information
### Instructor: Mayur Naik
- Credit Units: 1 CU
- Class Schedule: Lectures during 1:45-3:15 pm on Mon/Wed in WLNT 401B; occasional recitations on Fridays
### Prerequisites:
- CIS 5200 or equivalent: Mathematical foundations of machine learning
- CIS 5450 or equivalent: Experience with building, training, and debugging machine learning models
- Text/Required Materials: Selected papers from machine learning conferences (e.g., NeurIPS, ICML, ICLR)
### Course Description
This course offers an in-depth exploration of large language models (LLMs) focusing on their design, training, and usage. It begins with the attention mechanism and transformer architectures, moves through practical aspects of pre-training and efficient deployment, and concludes with advanced techniques like prompting and neurosymbolic learning. The course aims to equip students with the skills to critically analyze LLM research and apply these concepts in real-world scenarios. A solid foundation in machine learning, programming, and deep learning is recommended.

### Topics Covered
- History of LLMs
- Transformer Architectures
- Model Training Techniques
- Prompt Engineering
- Ethical Considerations and Safety Measures
- Advanced Integration Techniques (e.g., RAG, Agents, Neurosymbolic Learning)
